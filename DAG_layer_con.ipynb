{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462c180f",
   "metadata": {},
   "source": [
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import textwrap\n",
    "import heapq\n",
    "from collections import Counter\n",
    "from itertools import cycle, islice\n",
    "from typing import (\n",
    "    Callable, List, Tuple, Sequence, Set,\n",
    "    Hashable, Dict, Iterable, Union, Pattern, Optional\n",
    ")\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import DAG_functions as dag_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af63a4",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_file_path = '/Users/qingyuanzheng/Documents/VScode/Agent/WF_objects/Drain_CPD_LLM/results/time_series/gnb_10m_20m(Drain_mid).pkl'\n",
    "log_file = '/Users/qingyuanzheng/Documents/VScode/Agent/WF_objects/Drain_CPD_LLM/log/gnb_10m_20m.log' \n",
    "log_cluster_path = '/Users/qingyuanzheng/Documents/VScode/Agent/WF_objects/Drain_CPD_LLM/results/cluster_results/gnb_10m_20m(Drain_mid).txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning UE 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning UE 0: 100%|██████████| 3319232/3319232 [00:02<00:00, 1597752.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning UE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning UE 1: 100%|██████████| 3319232/3319232 [00:02<00:00, 1244163.68it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(sig_file_path, 'rb') as f:\n",
    "    signals = pickle.load(f)\n",
    "with open(log_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "layer_patterns = {\n",
    "    'PDCP': r'\\[PDCP\\s*\\]',\n",
    "    'RLC': r'\\[RLC\\s*\\]',\n",
    "    'MAC': r'\\[MAC\\s*\\]'\n",
    "}\n",
    "\n",
    "ue_idx_list = dag_func.get_ue_idx_list(lines, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDCP: [192, 191, 193, 194, 195, 197, 71, 124, 70, 72, 73, 74, 75, 93, 94, 115, 121, 122, 123, 126, 127, 114, 118, 119, 32, 33, 128, 138, 142, 120, 135, 136, 137, 141, 143, 144, 145, 146, 201, 202, 203, 204, 222, 223, 236, 237, 238, 239]\n",
      "GTPU: [196, 3, 133, 134, 257, 2, 198, 199, 200]\n",
      "RLC:  [175, 177, 178, 179, 174, 176, 185, 186, 187, 188, 183, 189, 190, 172, 173, 181, 182, 184, 207, 206, 226, 225, 209, 220, 228, 240, 247, 248, 36, 35, 88, 90, 42, 63, 65, 66, 67, 68, 69, 76, 77, 78, 79, 80, 81, 64, 82, 89, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 108, 109, 111, 112, 113, 110, 253, 254, 22, 23, 41, 20, 21, 30, 34, 43, 44, 45, 147, 148, 154, 255, 256, 205, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 230, 231, 232, 233, 234, 235]\n",
      "MAC:  [61, 180, 91, 224, 227, 243, 208, 242, 246, 244, 60, 249, 130, 107, 245, 171, 250, 105, 46, 19, 24, 25, 26, 27, 28, 29, 149, 150, 151, 152, 47, 161, 229, 252]\n",
      "SCHED: [17, 11, 14, 158, 50, 241, 156, 251, 51, 83]\n",
      "OTHER: [6, 7, 8, 1, 4, 5, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def tag_select(all_paths_MG, log_cluster_path):\n",
    "    with open(log_cluster_path) as f:\n",
    "        log_cluster_lines = f.readlines()\n",
    "\n",
    "\n",
    "    matched_logs_tuples = dag_func.extract_log_tuples(log_cluster_lines, all_paths_MG)\n",
    "\n",
    "    filtered_logs_tuples = dag_func.trim_after_last_period(matched_logs_tuples) \n",
    "    \n",
    "    return filtered_logs_tuples, matched_logs_tuples\n",
    "\n",
    "\n",
    "with open(log_cluster_path) as f:\n",
    "    log_cluster_lines = f.readlines()\n",
    "\n",
    "pattern = re.compile(\n",
    "    r'ID=(\\d+)'              \n",
    "    r'.*?'                   \n",
    "    r'\\[\\s*([^\\]\\s]+)\\s*\\]'  \n",
    ")\n",
    "\n",
    "component_to_category = {\n",
    "    'PDCP': 'PDCP',\n",
    "    'GTPU': 'GTPU',\n",
    "    'RLC':  'RLC',\n",
    "    'MAC':  'MAC',\n",
    "    'SCHED':'SCHED'\n",
    "}\n",
    "\n",
    "def classify_ids(log_cluster_lines):\n",
    "    pdcp_ids, gtp_u_ids = [], []\n",
    "    rlc_ids, mac_ids = [], []\n",
    "    sched_ids, other_ids = [], []\n",
    "\n",
    "    for line in log_cluster_lines:\n",
    "        m = pattern.search(line)\n",
    "        if not m:\n",
    "            continue\n",
    "        event_id = int(m.group(1))\n",
    "        comp     = m.group(2)\n",
    "        cat = component_to_category.get(comp, 'OTHER')\n",
    "        if cat == 'PDCP':\n",
    "            pdcp_ids.append(event_id)\n",
    "        elif cat == 'GTPU':\n",
    "            gtp_u_ids.append(event_id)\n",
    "        elif cat == 'RLC':\n",
    "            rlc_ids.append(event_id)\n",
    "        elif cat == 'MAC':\n",
    "            mac_ids.append(event_id)\n",
    "        elif cat == 'SCHED':\n",
    "            sched_ids.append(event_id)\n",
    "        else:\n",
    "            other_ids.append(event_id)\n",
    "\n",
    "    return pdcp_ids, gtp_u_ids, rlc_ids, mac_ids, sched_ids, other_ids\n",
    "\n",
    "\n",
    "pdcp_ids, gtp_u_ids, rlc_ids, mac_ids, sched_ids, other_ids = classify_ids(log_cluster_lines)\n",
    "print(\"PDCP:\", pdcp_ids)\n",
    "print(\"GTPU:\", gtp_u_ids)\n",
    "print(\"RLC: \", rlc_ids)\n",
    "print(\"MAC: \", mac_ids)\n",
    "print(\"SCHED:\", sched_ids)\n",
    "print(\"OTHER:\", other_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to select a specific UE, you can use the following code\n",
    "ue0_idx_list = ue_idx_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0991a",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744729f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_final(ue_idx_lists, lines, layer_patterns, window_size, step, log_cluster_path):\n",
    "    \n",
    "    refined_all_paths_MGs = []\n",
    "    refined_Ms = []\n",
    "    pruned_graphs_list = []\n",
    "    filtered_logs_tuples_list = []\n",
    "    all_paths_MG_list = []\n",
    "\n",
    "    \n",
    "    for idx, uex_idx_list in enumerate(ue_idx_lists):\n",
    "        \n",
    "        print(\"!!!!!!!!!!! Processing UEX idx:\", idx)\n",
    "        \n",
    "        uex_layer_idx = dag_func.classify_ue_layers(uex_idx_list, lines, layer_patterns)\n",
    "        print(\"Layer seperation finished\")\n",
    "        \n",
    "        uex_sig = dag_func.select_uex_sig(uex_idx_list, signals)\n",
    "        print(\"UE signal selection finished\")\n",
    "        print(\"ue0 signal length:\",  len(uex_sig))\n",
    "        \n",
    "        uex_layer_sig =[]\n",
    "\n",
    "        uex_rlc_sig = dag_func.select_uex_sig(uex_layer_idx['RLC'], signals)\n",
    "        uex_pdcp_sig = dag_func.select_uex_sig(uex_layer_idx['PDCP'], signals)\n",
    "        \n",
    "        # print(\"#rlc_sig_o:\", len(uex_rlc_sig_o))\n",
    "        \n",
    "        # uex_rlc_sig = select_uex_sig_aug(uex_layer_idx['RLC'], signals, layer='RLC')\n",
    "        # uex_pdcp_sig = select_uex_sig_aug(uex_layer_idx['PDCP'], signals, layer='PDCP')\n",
    "\n",
    "        print(\"UE rlc signal selection finished\")\n",
    "        \n",
    "        print(\"ue0 rlc layer signal length:\", len(uex_rlc_sig))\n",
    "        print(\"ue0 pdcp layer signal length:\", len(uex_pdcp_sig))\n",
    "        uex_layer_sig.append(uex_rlc_sig)\n",
    "        uex_layer_sig.append(uex_pdcp_sig)\n",
    "        layer_idx = 0\n",
    "        \n",
    "        for layer_sig in uex_layer_sig:\n",
    "            if layer_idx == 0:  \n",
    "                print(\"Processing rlc layer\")\n",
    "            else:\n",
    "                print(\"Processing pdcp layer\")\n",
    "            layer_idx += 1\n",
    "            \n",
    "            uex_layer_sig_slices = dag_func.sliding_windows_step(layer_sig, window_size, step)\n",
    "            uex_sig_slices = dag_func.sliding_windows_step(uex_sig, window_size, step)\n",
    "            print(\"uex rlc slices length:\", len(uex_layer_sig_slices))\n",
    "            print(\"uex sig slices length:\", len(uex_sig_slices))\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"Generating DAG for uex rlc slices...\")\n",
    "            traces = uex_layer_sig_slices.copy()\n",
    "            graphs_list, node_supports, edge_supports = dag_func.generate_DAG(traces)\n",
    "            print(\"DAG generation finished\")\n",
    "            \n",
    "            all_dag, dag_flags = dag_func.check_graphs_are_dag(graphs_list, False)\n",
    "            print(\"DAG checking finished\")\n",
    "            \n",
    "            graph_list, node_support_list, edge_support_list = dag_func.filter_graphs(dag_flags,graphs_list,node_supports,edge_supports)\n",
    "            print(\"Numbers of initial sub graphs\", len(graph_list))\n",
    "            print(\"Filtering finished\")\n",
    "            \n",
    "            forward_confidence, backward_confidence = dag_func.compute_all_confidences(\n",
    "                node_support_list,\n",
    "                edge_support_list,\n",
    "                dag_func.compute_confidences\n",
    "            )\n",
    "            print(\"Confidence calculation finished\")\n",
    "            \n",
    "            print(\"Pruning...\")\n",
    "            pruned_graphs = dag_func.prune_graphs(\n",
    "                graph_list,\n",
    "                forward_confidence,\n",
    "                backward_confidence,\n",
    "                threshold=0.3,\n",
    "                prune_causality_graph = dag_func.prune_causality_graph\n",
    "            )\n",
    "            print(\"Pruning finished\")\n",
    "            \n",
    "            print(\"Model selection...\")\n",
    "            all_paths = dag_func.model_selection(pruned_graphs, cutoff=None)\n",
    "            print(\"Model selection finished\")\n",
    "            \n",
    "            \n",
    "            all_paths_MG = dag_func.plot_model_paths(all_paths, layout=\"stair\", print_graph=False)\n",
    "            print(\"Model paths plotting finished\")\n",
    "            num_edges = dag_func.count_edges_in_graph(all_paths_MG)\n",
    "            print(f\"all_paths_MG has {num_edges} Edges\")\n",
    "            \n",
    "            filtered_logs_tuples, matched_logs_tuples = tag_select(all_paths_MG, log_cluster_path)\n",
    "            \n",
    "            print(\"Model evaluation...\")\n",
    "            \n",
    "            print(\"Sorting paths...\")\n",
    "            \n",
    "            sorted_paths = dag_func.compute_scores_multi(pruned_graphs, forward_confidence, backward_confidence)\n",
    "            \n",
    "            print(\"Model refinement...\")\n",
    "            \n",
    "            refined_M, final_AR, acc_list = dag_func.model_refinement(sorted_paths, all_paths, traces, accuracy_th=0.98, max_iteration=30)\n",
    "\n",
    "            refined_all_paths_MG = dag_func.plot_model_paths(refined_M, layout=\"stair\", print_graph=False)\n",
    "            \n",
    "            print(\"Drawing FSM...\")\n",
    "\n",
    "\n",
    "            dag_func.draw_layered_fsm_note(all_paths_MG,\n",
    "                filtered_logs_tuples,\n",
    "                prog=\"dot\",\n",
    "                rankdir=\"TB\",\n",
    "                nodesep=0.5,\n",
    "                ranksep=0.8,\n",
    "                figsize=(80, 70),\n",
    "                node_size=3000,\n",
    "                font_size=17,\n",
    "                arrowsize=60,\n",
    "                wrap_width=27,\n",
    "                y_offset_pts=-35\n",
    "                )\n",
    "\n",
    "            dag_func.draw_layered_fsm_note(refined_all_paths_MG,\n",
    "                filtered_logs_tuples,\n",
    "                prog=\"dot\",\n",
    "                rankdir=\"TB\",\n",
    "                nodesep=0.5,\n",
    "                ranksep=0.8,\n",
    "                figsize=(80, 70),\n",
    "                node_size=3000,\n",
    "                font_size=17,\n",
    "                arrowsize=60,\n",
    "                wrap_width=27,\n",
    "                y_offset_pts=-35\n",
    "                )\n",
    "            \n",
    "            acc_list.insert(0, 0)\n",
    "            dag_func.plot_model_refine_score(acc_list)\n",
    "            \n",
    "            all_paths_MG_list.append(all_paths_MG)\n",
    "            refined_all_paths_MGs.append(refined_all_paths_MG)\n",
    "            refined_Ms.append(refined_M)\n",
    "            pruned_graphs_list.append(pruned_graphs)\n",
    "            filtered_logs_tuples_list.append(filtered_logs_tuples)\n",
    "        break\n",
    "        \n",
    "    return refined_all_paths_MGs, all_paths_MG_list, refined_Ms, pruned_graphs_list, filtered_logs_tuples_list\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced630af",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_all_paths_MGs, all_paths_MG_list, refined_Ms, pruned_graphs_list, filtered_logs_tuples_list=graph_final(ue_idx_lists = ue_idx_list, lines = lines, layer_patterns = layer_patterns, window_size = 2000, step = 1500, log_cluster_path = log_cluster_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
